## Bayesian Normal, Pooled and Hierarchical Modelling 

Exploring the idea of independent modeling versus pooling versus partial pooling (via hierarchical modelling).  
This will look at a simple one-dimensional regression problem, i.e. a single predictor and a single outcome.  
There are eight different groups, with each group having its own slope, and a fixed intercept of zero. 
```{r}
#import packages
library(dplyr)
library(R2jags)
library(ggplot2)
library(tidybayes)
```

Below is some simulated data:
the slopes of the 8 sets have a mean of 2 and there is an across group variance of 0.2 on the slopes
group 7 and 8 have only 5 observations
group 3 and 4 have larger variance
```{r}
#method to simulate data

set.seed(28) # set the seed
mean_slope = 2 # the 8 different slopes have a mean of 2
sigma_slope = 0.2 # across group variation
slopes = rnorm(8,mean_slope,sigma_slope) # groups slopes vary around the mean
groups = c(rep(1:6,each = 14),rep(7,5), rep(8,5)) # some groups have smaller sample sizes
sigma <- c(0.5,0.5,2,2,0.5,2,0.5,0.5) # have some groups with large variation
x = rnorm(length(groups)) # simulate a predictor
y = slopes[groups]*x + rnorm(length(groups),0,sigma[groups]) # simulate y
y[length(groups)] <- 8 # add an outlier
sim_dat <- tibble(x = x, y = y, group = groups) # create the simulated dataset
```


```{r}
## Plot the simulated data
ggplot(sim_dat, aes(x = x, y = y)) +
geom_point() +
facet_wrap(~group)

#create a regular model for the data
reg_model_template = "
model{
for(i in 1:n)
{
y.i[i] ~ dnorm(mu.i[i],sigma^-2) # data model
mu.i[i] <- alpha + (beta.j[group[i]] * x.i[i])
} # end i loop

for(j in 1:m) {
beta.j[j] ~ dnorm(0, 10^-2)
}
 
alpha ~ dnorm(0, 2^-2)
sigma ~ dunif(0,30)

}
"

# call the data needed 
jags.data <- list(y.i = sim_dat$y,
                  x.i = sim_dat$x,
                  group = sim_dat$group,
                  n = nrow(sim_dat),
                  m = sim_dat$group %>% unique() %>% length())

parnames <- c("alpha", "beta.j", "sigma")

#write a jags script `mod` using the normal model
mod <- jags(data = jags.data,
            parameters.to.save = parnames,
            model.file = textConnection(reg_model_template),
            n.iter = 10000,
            n.burnin = 2000,
            n.thin=4)

#check convergence
plot(mod) 

#cretae sims.matrix for more convienient usage later
m <- mod$BUGSoutput$sims.matrix

true_slopes  <- tibble(slopes, group = factor(1:8))
group_ind <- 1:8

#spread_draws and plot the data
m %>% spread_draws(beta.j[group_ind]) %>%
  ggplot(aes(x = beta.j,y=factor(group_ind))) +
  stat_halfeye() +
  geom_point(data = true_slopes,aes(x = slopes, y = group, colour="true slope"))
```

Now create a hierarchical model that will  draw the beta.j's from a distribution
```{r}
bhreg_model_template = "
model{
for(i in 1:n)
{
y.i[i] ~ dnorm(mu.i[i],sigma^-2) # data model
mu.i[i] <- alpha +(beta.j[group[i]] * x.i[i])
} # end i loop

#new loop for beta.js
for(j in 1:m){ 
beta.j[j] ~ dnorm(beta_mu, sigma_beta^-2)
}

#set priors
beta_mu ~ dnorm(0,2^-2) #so we are adding the hyperparameter beta mu
alpha ~ dnorm(0,2^-2)
sigma ~ dt(0,2^-2,1)T(0,)
sigma_beta ~ dt(0,2^-2,1)T(0,)
}
"
#call in the data
jags.data <- list(y.i = sim_dat$y,
                  x.i = sim_dat$x,
                  group = sim_dat$group,
                  n = nrow(sim_dat),
                  m = sim_dat$group %>% unique() %>% length())

#set the names to save
parnames <- c("alpha", "beta.j", "sigma", "beta_mu", "sigma_beta")

#create jags script and attributes
mod <- jags(data = jags.data,
            parameters.to.save = parnames,
            model.file = textConnection(bhreg_model_template),
            n.iter = 10000,
            n.burnin = 2000,
            n.thin=4)

#check convergence
plot(mod)

#create a sims.matrix 
m <- mod$BUGSoutput$sims.matrix

#plot the hierarchical model and compare this to the normal model
m %>% spread_draws(beta.j[group_ind]) %>%
  ggplot(aes(x = beta.j,y=factor(group_ind))) +
  stat_halfeye() +
  geom_point(data = true_slopes,aes(x = slopes, y = group, colour="true slope"))
```

Now fit the unpooled model in order to compare to the normal and hierarchical models
```{r}

#fit an unpooled regression model
unpool = " model{
for(i in 1:n){
y.i[i] ~ dnorm(mu.i[i], sigma^-2)
mu.i[i] <- alpha + beta.j[group[i]] * (x.i[i]) #use the index
}
for(j in 1:m){
beta.j[j] ~ dnorm(0,10^-2)
}

alpha ~ dnorm(0,10^-2) #uninformative
sigma ~ dt(0,2^-2,1)T(0,) #uninformative
}
"

#call in the data needed 
jags.data <- list(y.i = sim_dat$y,
                  x.i = sim_dat$x,
                  group = sim_dat$group,
                  n = nrow(sim_dat),
                  m = length(unique(sim_dat$group)))

#names to save
parnames <- c("alpha", "beta.j", "sigma")

#create jags script with attributes
mod <- jags(data = jags.data,
            parameters.to.save = parnames,
            model.file = textConnection(unpool),
            n.iter = 10000,
            n.burnin = 2000,
            n.thin = 4)

#check convergence
plot(mod)

m <- mod$BUGSoutput$sims.matrix

#create group index to fit the data in order to plot
true_slopes <-tibble(slopes, group = factor(1:8))
group_ind <- 1:8

m %>% spread_draws(beta.j[group_ind]) %>%
  ggplot(aes(x = beta.j, y = factor(group_ind))) +
  stat_halfeye() +
  geom_point(data = true_slopes, aes(x = slopes, y = group, colour = "true slope"))

```


```{r}

bhm = " model{
for(i in 1:n){
y.i[i] ~ dnorm(mu.i[i],sigma^-2)
mu.i[i] <- alpha + beta.j[group[i]] * x.i[i]
} #end i loop

for(j in 1:m){
beta.j[j] ~ dnorm(beta_mu, sigma_beta^-2) #beta hyperparams
}

beta_mu ~ dnorm(0,2^-2) #hyper
alpha ~ dnorm(0,2^-2)
sigma ~ dt(0,2^-2,1)T(0,)
sigma_beta ~ dt(0,2^-2,1)T(0,) #hyper
}
"

jags.data <- list(y.i = sim_dat$y,
                  x.i = sim_dat$x,
                  group = sim_dat$group,
                  n = nrow(sim_dat),
                  m = length(unique(sim_dat$group)))
parnames <- c("alpha","beta.j", "sigma", "beta_mu","sigma_beta")

mod1 <- jags(data = jags.data,
             parameters.to.save = parnames,
             model.file = textConnection(bhm),
             n.iter = 10000,
             n.burnin = 2000,
             n.thin = 4)

m <- mod1$BUGSoutput$sims.matrix


true_slopes <-tibble(slopes, group = factor(1:8))
group_ind <- 1:8
m %>% spread_draws(beta.j[group_ind]) %>%
  ggplot(aes(x = beta.j, y = factor(group_ind))) +
  stat_halfeye() +
  geom_point(data = true_slopes, aes(x = slopes, y = group, colour = "true slopes"))

mod1$BUGSoutput$summary
```


```{r}
```


```{r}
```


```{r}
```

